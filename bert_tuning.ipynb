{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b354e896",
   "metadata": {},
   "source": [
    "# Fine-Tuning BERT\n",
    "\n",
    "> Let's try fine-tuning a BERT model for reddit rule violation prediction!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3389d43c",
   "metadata": {},
   "source": [
    "## Idea\n",
    "\n",
    "- replace model's top layer with binary classification head\n",
    "- fine tune our LLM on training data\n",
    "    - actually, this would allow us to quintuple our training data, by also including positive and negative examples\n",
    "    - could even include negative and positive examples from test data\n",
    "- we need to create a custom huggingface dataset from the csv or a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce32800d",
   "metadata": {
    "tags": [
     "setup",
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import transformers\n",
    "import torch\n",
    "import seaborn as sns\n",
    "\n",
    "# in Kaggle, add evaluate to depedencies!\n",
    "# however, you need internet to install additional dependencies...\n",
    "# import evaluate\n",
    "\n",
    "from datasets import Dataset, load_dataset\n",
    "from pathlib import Path\n",
    "from torch.nn.functional import softmax\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "\n",
    "COMPETITION_HANDLE = \"jigsaw-agile-community-rules\"\n",
    "\n",
    "BERT_HANDLE = \"google-bert/bert-base-cased\"\n",
    "BERT_PATH = \"/kaggle/input/bert-base-cased/transformers/default/1\"\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e45e4d5",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c9d8e0",
   "metadata": {},
   "source": [
    "- need a model for Sequence Classification\n",
    "- would like to use a BERT model for sequence classification\n",
    "    - unfortunately, `kagglehub` does not offer `BERT` for the `transformers` framework\n",
    "    - could use transformers `TFAutoModel` class to instantiate `tensorflow` models\n",
    "    - but we cannot use `tensorflow` in our local environment, as it requires CUDA 12.3, and we only have CUDA 12.2\n",
    "    - could use `transformers` to download `bert-base-cased`\n",
    "    - but if we want to submit our notebook to the competition, it is supposed to run without `internet access`!\n",
    "    - so downloads from `transformers` will fail...\n",
    "- alternative: stick with `gemma-3` for sequence classification\n",
    "    - however: transformers does not seem to support `gemma-3-1b` for sequence classification out of the box...\n",
    "    - however, does support `gemma-3-4b` for sequence classification though\n",
    "    - but `gemma-3-4b` is too big to be fine-tuned!\n",
    "        - while for inference, gemma-3-4b only requires `2 byte * 4b params + kv-cache ~ 10GB` VRAM for inference, for fine-tuning we also need to store all activations on the GPU for backpropagating the gradients...\n",
    "        - Quantization doesn't help, because the parameters are inflated to 16 bit again\n",
    "- conclusion: use bert, download it beforehand and upload it on kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e9f43ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # try to download BERT from huggingface\n",
    "    # add classification head to model\n",
    "    # instantiate BERT, but use 2 output classification head (num_labels=2)\n",
    "    bert_model = AutoModelForSequenceClassification.from_pretrained(BERT_HANDLE, num_labels=2)\n",
    "    bert_model.to(DEVICE)\n",
    "    bert_tokenizer = AutoTokenizer.from_pretrained(BERT_HANDLE)\n",
    "except OSError:\n",
    "    # if we have no internet connection, load bert from local path instead\n",
    "    bert_model = AutoModelForSequenceClassification.from_pretrained(BERT_PATH, num_labels=2)\n",
    "    bert_model.to(DEVICE)\n",
    "    bert_tokenizer = AutoTokenizer.from_pretrained(BERT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b25f8e",
   "metadata": {},
   "source": [
    "When instantiating the Sequence Classification model, you will probably see a warning like: \n",
    "\n",
    "> Some weights were not initialized from the model checkpoint and are newly initialized: [...]\n",
    "> You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
    "\n",
    "The pretrained model already brings it's own classification head.\n",
    "But since we only want to do binary classification if the reddit rule is violated or not, we replaced the classification head with just 2 output neurons.\n",
    "However, the parameters (weights) of the classification head are now randomly initialized and not adjusted to the task at all.\n",
    "If we would use the model as is, we will receive random Yes or No predictions for rule violations.\n",
    "\n",
    "Therefore, we need to *fine-tune* the model to the downstream task on our dataset of reddit comments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9811f03",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "Since we are now finetuning the model instead of doing few-shot In-Context-Learning, we don't actually need the positive and negative examples in the prompt.\n",
    "However, instead of just discarding them, we could use them as additional training examples, effectively quintupling the size of our training dataset!\n",
    "We will save this preprocessed dataset as csv.\n",
    "\n",
    "We need to wrap our dataset in a `transformers` Dataset object, which the Trainer expects.\n",
    "Then, we need to construct the right input prompts given our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d79f49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/.cache/kagglehub/competitions/jigsaw-agile-community-rules\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = Path(kagglehub.competition_download(COMPETITION_HANDLE))\n",
    "\n",
    "print(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbc8ff1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = DATA_PATH / \"train.csv\"\n",
    "TEST_PATH = DATA_PATH / \"test.csv\"\n",
    "SAMPLE_PATH = DATA_PATH / \"sample_submission.csv\"\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "test_df = pd.read_csv(TEST_PATH)\n",
    "sample_df = pd.read_csv(SAMPLE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61d6eab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_examples(df: pd.DataFrame):\n",
    "    positive_mask = df[\"variable\"].str.contains(\"positive\")\n",
    "    negative_mask = df[\"variable\"].str.contains(\"negative\")\n",
    "\n",
    "    df.loc[negative_mask, \"labels\"] = 0\n",
    "    df.loc[positive_mask, \"labels\"] = 1\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def preprocess_train(df: pd.DataFrame):\n",
    "    df = df.rename(columns={\"rule_violation\": \"labels\"})\n",
    "    df = df.melt(id_vars=[\"row_id\", \"rule\", \"subreddit\", \"labels\"])\n",
    "    df = label_examples(df)\n",
    "    return df\n",
    "\n",
    "def preprocess_test(df: pd.DataFrame):\n",
    "    example_cols = [c for c in df.columns if \"example\" in c]\n",
    "    df = df.drop(columns=example_cols)\n",
    "    df = df.melt(id_vars=[\"row_id\", \"rule\", \"subreddit\"])\n",
    "    return df\n",
    "\n",
    "def preprocess_val(df: pd.DataFrame):\n",
    "    df = df.drop(columns=\"body\")\n",
    "    df = df.melt(id_vars=[\"row_id\", \"rule\", \"subreddit\"])\n",
    "    df = label_examples(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "313deaaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>rule</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>labels</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>Futurology</td>\n",
       "      <td>0</td>\n",
       "      <td>body</td>\n",
       "      <td>Banks don't want you to know this! Click here ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>soccerstreams</td>\n",
       "      <td>0</td>\n",
       "      <td>body</td>\n",
       "      <td>SD Stream [ ENG Link 1] (http://www.sportsstre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>No legal advice: Do not offer or request legal...</td>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td>1</td>\n",
       "      <td>body</td>\n",
       "      <td>Lol. Try appealing the ban and say you won't d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>sex</td>\n",
       "      <td>1</td>\n",
       "      <td>body</td>\n",
       "      <td>she will come your home open her legs with  an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>hearthstone</td>\n",
       "      <td>1</td>\n",
       "      <td>body</td>\n",
       "      <td>code free tyrande ---&gt;&gt;&gt; [Imgur](http://i.imgu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id                                               rule      subreddit  \\\n",
       "0       0  No Advertising: Spam, referral links, unsolici...     Futurology   \n",
       "1       1  No Advertising: Spam, referral links, unsolici...  soccerstreams   \n",
       "2       2  No legal advice: Do not offer or request legal...   pcmasterrace   \n",
       "3       3  No Advertising: Spam, referral links, unsolici...            sex   \n",
       "4       4  No Advertising: Spam, referral links, unsolici...    hearthstone   \n",
       "\n",
       "   labels variable                                              value  \n",
       "0       0     body  Banks don't want you to know this! Click here ...  \n",
       "1       0     body  SD Stream [ ENG Link 1] (http://www.sportsstre...  \n",
       "2       1     body  Lol. Try appealing the ban and say you won't d...  \n",
       "3       1     body  she will come your home open her legs with  an...  \n",
       "4       1     body  code free tyrande --->>> [Imgur](http://i.imgu...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TUNE_PATH = Path(\"data/tune/\")\n",
    "TUNE_PATH.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "TUNE_TRAIN_PATH = TUNE_PATH / \"train.csv\"\n",
    "TUNE_VAL_PATH = TUNE_PATH / \"val.csv\"\n",
    "TUNE_TEST_PATH = TUNE_PATH / \"test.csv\"\n",
    "\n",
    "\n",
    "tune_train_df = preprocess_train(train_df)\n",
    "tune_train_df.to_csv(TUNE_TRAIN_PATH, index=False)\n",
    "\n",
    "tune_val_df = preprocess_val(test_df)\n",
    "tune_val_df.to_csv(TUNE_VAL_PATH, index=False)\n",
    "\n",
    "\n",
    "tune_test_df = preprocess_test(test_df)\n",
    "tune_test_df.to_csv(TUNE_TEST_PATH, index=False)\n",
    "\n",
    "tune_train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "033ecab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4343e33ff21f464c8a85eb587c0e164c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d6cb1e19f7244f6be379b03d41b1955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating val split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dbfeed7b1c44ecb81860d413713a532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "tune_ds = load_dataset(\"csv\", data_files={\n",
    "    \"train\": str(TUNE_TRAIN_PATH),\n",
    "    \"val\": str(TUNE_VAL_PATH),\n",
    "    \"test\": str(TUNE_TEST_PATH)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10eee128",
   "metadata": {},
   "source": [
    "Great, now we need to map our prompt template and the tokenizer on each example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd446472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a7c98fbfe7041aaa0f814eb999478cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10145 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c26ad854dc9d4d70b96ade12f3ed02f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0034aa01ddfc424394ffcd91b3129c12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [SUBREDDIT]\n",
      "    Futurology\n",
      "    [RULE]\n",
      "    No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.\n",
      "    [CONTENT]\n",
      "    Banks don't want you to know this! Click here to know more!\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "def apply_template(example):\n",
    "    template = \"\"\"\\\n",
    "    [SUBREDDIT]\n",
    "    {subreddit}\n",
    "    [RULE]\n",
    "    {rule}\n",
    "    [CONTENT]\n",
    "    {value}\n",
    "    \"\"\"\n",
    "    example[\"prompt\"] = template.format(subreddit=example[\"subreddit\"], rule=example[\"rule\"], value=example[\"value\"])\n",
    "    return example\n",
    "\n",
    "tune_ds = tune_ds.map(apply_template)\n",
    "\n",
    "print(tune_ds[\"train\"][0][\"prompt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57f7057d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2402ccb22d464b0dbe2e9c50538e6e40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10145 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "892d9ee8e7d94ad7ad56e3fa0479924b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "747aa76db3e843fb80ff3604800c9d8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 164, 156, 2591, 26166, 10069, 17243, 1942, 166, 14763, 20362, 4807, 164, 155, 2591, 17516, 166, 1302, 25010, 131, 23665, 1306, 117, 5991, 4412, 6743, 117, 8362, 24313, 22308, 1174, 6437, 117, 1105, 10626, 3438, 1132, 1136, 2148, 119, 164, 18732, 15681, 11680, 1942, 166, 10117, 1274, 112, 189, 1328, 1128, 1106, 1221, 1142, 106, 140, 13299, 1303, 1106, 1221, 1167, 106, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "def apply_tokenizer(examples):\n",
    "    return bert_tokenizer(examples[\"prompt\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tune_ds = tune_ds.map(apply_tokenizer, batched=True)\n",
    "\n",
    "print(tune_ds[\"train\"][0][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee64adf5",
   "metadata": {},
   "source": [
    "### Finetuning the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63855b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"models/reddit_classifier\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    # in kaggle, wandb is installed and will raise an error without API token...\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    probas = softmax(torch.from_numpy(logits), dim=1).numpy()\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # compute via evaluate\n",
    "    # return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(labels, predictions),\n",
    "        \"f1\": f1_score(labels, predictions),\n",
    "        \"roc_auc\": roc_auc_score(labels, probas[:, 1])\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "\n",
    "# ensures, that all inputs in a batch are padded to the same length\n",
    "# data_collator = DataCollatorWithPadding(tokenizer=bert_tokenizer, padding=True)\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=bert_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tune_ds[\"train\"],\n",
    "    eval_dataset=tune_ds[\"val\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "#    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8160d4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fine-tuning\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:09, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.689457</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.672500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.684196</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.697500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.668402</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.707500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=39, training_loss=0.6830650231777093, metrics={'train_runtime': 9.5962, 'train_samples_per_second': 31.263, 'train_steps_per_second': 4.064, 'total_flos': 78933316608000.0, 'train_loss': 0.6830650231777093, 'epoch': 3.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"start fine-tuning\")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5961e1fd",
   "metadata": {},
   "source": [
    "### Predict on Test examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efc2d441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.5096333 , 0.5220407 , 0.5062994 , 0.47678885, 0.52223575,\n",
       "       0.6111362 , 0.57424563, 0.43309432, 0.5075619 , 0.5197084 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = trainer.predict(tune_ds[\"test\"])\n",
    "pred_labels = np.argmax(pred.predictions, axis=1)\n",
    "\n",
    "pred_proba = softmax(torch.from_numpy(pred.predictions), dim=1).numpy()[:, 1]\n",
    "pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "168e8431",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({\"row_id\": test_df[\"row_id\"], \"rule_violation\": pred_proba})\n",
    "submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d70a9b",
   "metadata": {},
   "source": [
    "## Bookmarks\n",
    "\n",
    "- kaggle:\n",
    "    - https://github.com/Kaggle/kagglehub\n",
    "    - https://www.kaggle.com/models\n",
    "- huggingface:\n",
    "    - https://huggingface.co/\n",
    "    - https://huggingface.co/docs/transformers/en/training\n",
    "    - https://huggingface.co/google-bert/bert-base-uncased"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e44474",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
